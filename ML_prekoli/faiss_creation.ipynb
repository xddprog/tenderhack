{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-multilingual-cased. Creating a new one with mean pooling.\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1680, which is longer than the specified 1000\n",
      "Created a chunk of size 1850, which is longer than the specified 1000\n",
      "Created a chunk of size 3113, which is longer than the specified 1000\n",
      "Created a chunk of size 1439, which is longer than the specified 1000\n",
      "Created a chunk of size 1448, which is longer than the specified 1000\n",
      "Created a chunk of size 1080, which is longer than the specified 1000\n",
      "Created a chunk of size 1181, which is longer than the specified 1000\n",
      "Created a chunk of size 2125, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1102, which is longer than the specified 1000\n",
      "Created a chunk of size 1009, which is longer than the specified 1000\n",
      "Created a chunk of size 1439, which is longer than the specified 1000\n",
      "Created a chunk of size 1231, which is longer than the specified 1000\n",
      "Created a chunk of size 2446, which is longer than the specified 1000\n",
      "Created a chunk of size 1026, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty or invalid description for article: Участие в котировочной сессии\n",
      "Skipping empty or invalid description for article: Уведомления о наступающих сроках исполнения этапа\n",
      "Skipping empty or invalid description for article: Видео\n",
      "Skipping empty or invalid description for article: Заказчику не приходит УПД\n",
      "Skipping empty or invalid description for article: Карта сайта\n",
      "Skipping empty or invalid description for article: Несанкционированное вмешательство в Подсистему\n",
      "Skipping empty or invalid description for article: Настройка MS Word перед работой\n",
      "Skipping empty or invalid description for article: Работа с контрактами, Мои контракты\n",
      "Skipping empty or invalid description for article: Список аккредитованных удостоверяющих центров\n",
      "Skipping empty or invalid description for article: Как в Исполнении контрактов, электронно актируемых через ЕИС, указать КПП крупнейшем налогоплательщике, и что делать, если у организации 2 и более КПП\n",
      "Skipping empty or invalid description for article: Тестовая статья\n",
      "Skipping empty or invalid description for article: Автоставки\n",
      "Skipping empty or invalid description for article: Ответ на уведомление об уточнении - создание исправительного УПД в исполнении через ЕИС\n",
      "Skipping empty or invalid description for article: Новая статья про котировочные сессии 1\n",
      "Skipping empty or invalid description for article: Тест\n",
      "Title vector store saved to 'title_faiss_index'\n",
      "Description chunk vector store saved to 'chunk_faiss_index'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def create_and_save_vector_db(\n",
    "    xls_path='Статьи.xls',\n",
    "    title_index_path='title_faiss_index',\n",
    "    chunk_index_path='chunk_faiss_index',\n",
    "    chunk_size=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and save FAISS vector stores for a two-step RAG pipeline.\n",
    "\n",
    "    Args:\n",
    "        xls_path (str): Path to the Excel file.\n",
    "        title_index_path (str): Directory to save the title FAISS index.\n",
    "        chunk_index_path (str): Directory to save the description chunk FAISS index.\n",
    "        chunk_size (int): Size of description chunks in characters.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(xls_path)\n",
    "    if 'Заголовок статьи' not in df.columns or 'Описание' not in df.columns:\n",
    "        raise ValueError(\"Excel file must contain 'Заголовок статьи' and 'Описание' columns\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='bert-base-multilingual-cased')\n",
    "    \n",
    "    # Create title documents\n",
    "    title_docs = [\n",
    "        Document(page_content=row['Заголовок статьи'], metadata={'article': row['Заголовок статьи']})\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Create description chunk documents with error handling\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunk_docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        article = row['Заголовок статьи']\n",
    "        description = row['Описание']\n",
    "        \n",
    "        # Convert description to string and handle NaN or non-string types\n",
    "        if pd.isna(description):\n",
    "            description = \"\"  # Replace NaN with empty string\n",
    "        else:\n",
    "            description = str(description)  # Ensure it's a string\n",
    "        \n",
    "        # Only split if description has content\n",
    "        if description.strip():\n",
    "            chunks = text_splitter.split_text(description)\n",
    "            for chunk in chunks:\n",
    "                doc = Document(page_content=chunk, metadata={'article': article})\n",
    "                chunk_docs.append(doc)\n",
    "        else:\n",
    "            print(f\"Skipping empty or invalid description for article: {article}\")\n",
    "    \n",
    "    # Create and save the title vector store\n",
    "    title_vector_store = FAISS.from_documents(title_docs, embeddings)\n",
    "    title_vector_store.save_local(title_index_path)\n",
    "    \n",
    "    # Create and save the description chunk vector store\n",
    "    chunk_vector_store = FAISS.from_documents(chunk_docs, embeddings)\n",
    "    chunk_vector_store.save_local(chunk_index_path)\n",
    "    \n",
    "    print(f\"Title vector store saved to '{title_index_path}'\")\n",
    "    print(f\"Description chunk vector store saved to '{chunk_index_path}'\")\n",
    "\n",
    "# Run the function\n",
    "create_and_save_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
